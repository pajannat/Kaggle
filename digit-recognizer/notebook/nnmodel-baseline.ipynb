{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-01-15T04:35:41.427832Z","iopub.execute_input":"2023-01-15T04:35:41.428279Z","iopub.status.idle":"2023-01-15T04:35:41.439349Z","shell.execute_reply.started":"2023-01-15T04:35:41.428244Z","shell.execute_reply":"2023-01-15T04:35:41.438167Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"/kaggle/input/digit-recognizer/sample_submission.csv\n/kaggle/input/digit-recognizer/train.csv\n/kaggle/input/digit-recognizer/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"# Import Libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom torch.utils.data import DataLoader\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport torch.nn.functional as F\nfrom torchvision import datasets, transforms","metadata":{"execution":{"iopub.status.busy":"2023-01-15T04:35:41.444829Z","iopub.execute_input":"2023-01-15T04:35:41.445601Z","iopub.status.idle":"2023-01-15T04:35:41.455840Z","shell.execute_reply.started":"2023-01-15T04:35:41.445543Z","shell.execute_reply":"2023-01-15T04:35:41.454627Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Prepare Dataset\n# load data\ntrain = pd.read_csv(r\"/kaggle/input/digit-recognizer/train.csv\",dtype = np.float32)\n\n# split data into features(pixels) and labels(numbers from 0 to 9)\ntargets_numpy = train.label.values\nfeatures_numpy = train.loc[:,train.columns != \"label\"].values/255 # normalization\n\n# train test split. Size of train data is 80% and size of test data is 20%. \nfeatures_train, features_valid, targets_train, targets_valid = train_test_split(features_numpy,\n                                                                             targets_numpy,\n                                                                             test_size = 0.2,\n                                                                             random_state = 42) \n# create feature and targets tensor for train set. As you remember we need variable to accumulate gradients. Therefore first we create tensor, then we will create variable\nfeaturesTrain = torch.from_numpy(features_train)\ntargetsTrain = torch.from_numpy(targets_train).type(torch.LongTensor) # data type is long\n\n# create feature and targets tensor for test set.\nfeaturesValid = torch.from_numpy(features_valid)\ntargetsValid = torch.from_numpy(targets_valid).type(torch.LongTensor) # data type is long\n\n# batch_size, epoch and iteration\nbatch_size = 100\nn_iters = 10000\nnum_epochs = n_iters / (len(features_train) / batch_size)\nnum_epochs = int(num_epochs)\n\n# Pytorch train and valid sets\ntrain = torch.utils.data.TensorDataset(featuresTrain,targetsTrain)\nvalid = torch.utils.data.TensorDataset(featuresValid,targetsValid)\n\n\n# data loader\ntrain_loader = DataLoader(train, batch_size = batch_size, shuffle = False)\nvalid_loader = DataLoader(valid, batch_size = batch_size, shuffle = False)","metadata":{"execution":{"iopub.status.busy":"2023-01-15T04:35:41.461831Z","iopub.execute_input":"2023-01-15T04:35:41.462765Z","iopub.status.idle":"2023-01-15T04:35:44.848499Z","shell.execute_reply.started":"2023-01-15T04:35:41.462713Z","shell.execute_reply":"2023-01-15T04:35:44.847622Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# visualize one of the images in data set\nplt.imshow(features_numpy[5].reshape(28,28))\n# plt.axis(\"off\")\nplt.title(str(targets_numpy[5]))\nplt.savefig('graph.png')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-01-15T04:35:44.850644Z","iopub.execute_input":"2023-01-15T04:35:44.851805Z","iopub.status.idle":"2023-01-15T04:35:45.135441Z","shell.execute_reply.started":"2023-01-15T04:35:44.851756Z","shell.execute_reply":"2023-01-15T04:35:45.134628Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"# Create NN Model\nclass NNModel(nn.Module):\n    def __init__(self, input_size, output_size):\n        super(NNModel, self).__init__()\n\n        # 各クラスのインスタンス（入出力サイズなどの設定）\n        self.fc1 = nn.Linear(input_size, 100)\n        self.fc2 = nn.Linear(100, output_size)\n\n    def forward(self, x):\n        # 順伝播の設定（インスタンスしたクラスの特殊メソッド(__call__)を実行）\n        x = self.fc1(x)\n        x = torch.sigmoid(x)\n        x = self.fc2(x)\n        return F.log_softmax(x, dim=1)","metadata":{"execution":{"iopub.status.busy":"2023-01-15T04:35:45.136855Z","iopub.execute_input":"2023-01-15T04:35:45.137388Z","iopub.status.idle":"2023-01-15T04:35:45.145584Z","shell.execute_reply.started":"2023-01-15T04:35:45.137325Z","shell.execute_reply":"2023-01-15T04:35:45.144196Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# ニューラルネットワークの生成\nimage_size = 28*28      # 画像の画素数(幅x高さ)\n# GPU(CUDA)が使えるかどうか？\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nlearning_rate = 0.001   # 学習率\n\nmodel = NNModel(image_size, 10).to(device)\n\n# 損失関数の定義\ncriterion = nn.CrossEntropyLoss() \n\n# 最適化手法の設定\noptimizer = torch.optim.Adam(model.parameters(), lr = learning_rate) ","metadata":{"execution":{"iopub.status.busy":"2023-01-15T04:35:45.149652Z","iopub.execute_input":"2023-01-15T04:35:45.150657Z","iopub.status.idle":"2023-01-15T04:35:45.167472Z","shell.execute_reply.started":"2023-01-15T04:35:45.150602Z","shell.execute_reply":"2023-01-15T04:35:45.166312Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# 学習\nmodel.train()  # モデルを訓練モードにする\n\nfor epoch in range(num_epochs): # 学習を繰り返し行う\n    loss_sum = 0\n\n    for inputs, labels in train_loader:\n\n        # GPUが使えるならGPUにデータを送る\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n\n        # optimizerを初期化\n        optimizer.zero_grad()\n\n        # ニューラルネットワークの処理を行う\n        inputs = inputs.view(-1, image_size) # 画像データ部分を一次元へ並び変える\n        outputs = model(inputs)\n\n        # 損失(出力とラベルとの誤差)の計算\n        loss = criterion(outputs, labels)\n        loss_sum += loss\n\n        # 勾配の計算\n        loss.backward()\n\n        # 重みの更新\n        optimizer.step()\n\n    # 学習状況の表示\n    print(f\"Epoch: {epoch+1}/{num_epochs}, Loss: {loss_sum.item() / len(train_loader)}\")\n\n    # モデルの重みの保存\n    torch.save(model.state_dict(), 'model_weights.pth')","metadata":{"execution":{"iopub.status.busy":"2023-01-15T04:35:45.170221Z","iopub.execute_input":"2023-01-15T04:35:45.171406Z","iopub.status.idle":"2023-01-15T04:36:08.580423Z","shell.execute_reply.started":"2023-01-15T04:35:45.171356Z","shell.execute_reply":"2023-01-15T04:36:08.578916Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Epoch: 1/29, Loss: 0.8998098827543712\nEpoch: 2/29, Loss: 0.33875267846243723\nEpoch: 3/29, Loss: 0.26408461162022184\nEpoch: 4/29, Loss: 0.22520939509073892\nEpoch: 5/29, Loss: 0.1974175771077474\nEpoch: 6/29, Loss: 0.17555039269583567\nEpoch: 7/29, Loss: 0.1576430911109561\nEpoch: 8/29, Loss: 0.14260710988725936\nEpoch: 9/29, Loss: 0.12974328086489723\nEpoch: 10/29, Loss: 0.1185454527537028\nEpoch: 11/29, Loss: 0.1086501848129999\nEpoch: 12/29, Loss: 0.09981095223199754\nEpoch: 13/29, Loss: 0.09185777959369477\nEpoch: 14/29, Loss: 0.08466034843808129\nEpoch: 15/29, Loss: 0.07810955955868676\nEpoch: 16/29, Loss: 0.07211425190880186\nEpoch: 17/29, Loss: 0.0666049321492513\nEpoch: 18/29, Loss: 0.061527882303510396\nEpoch: 19/29, Loss: 0.056837422507149835\nEpoch: 20/29, Loss: 0.052493770917256675\nEpoch: 21/29, Loss: 0.048462163834344776\nEpoch: 22/29, Loss: 0.044713119665781655\nEpoch: 23/29, Loss: 0.041222160770779566\nEpoch: 24/29, Loss: 0.03796885978607904\nEpoch: 25/29, Loss: 0.03493611869357881\nEpoch: 26/29, Loss: 0.03210948478607904\nEpoch: 27/29, Loss: 0.029476191316332136\nEpoch: 28/29, Loss: 0.0270243003254845\nEpoch: 29/29, Loss: 0.02474266290664673\n","output_type":"stream"}]},{"cell_type":"code","source":"#----------------------------------------------------------\n# 評価\nmodel.eval()  # モデルを評価モードにする\n\nloss_sum = 0\ncorrect = 0\n\nwith torch.no_grad():\n    for inputs, labels in valid_loader:\n\n        # GPUが使えるならGPUにデータを送る\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n\n        # ニューラルネットワークの処理を行う\n        inputs = inputs.view(-1, image_size) # 画像データ部分を一次元へ並び変える\n        outputs = model(inputs)\n\n        # 損失(出力とラベルとの誤差)の計算\n        loss_sum += criterion(outputs, labels)\n\n        # 正解の値を取得\n        pred = outputs.argmax(1)\n        # 正解数をカウント\n        correct += pred.eq(labels.view_as(pred)).sum().item()\n\nprint(f\"Loss: {loss_sum.item() / len(valid_loader)}, Accuracy: {100*correct/len(valid)}% ({correct}/{len(valid)})\")","metadata":{"execution":{"iopub.status.busy":"2023-01-15T04:36:08.582720Z","iopub.execute_input":"2023-01-15T04:36:08.583107Z","iopub.status.idle":"2023-01-15T04:36:08.709079Z","shell.execute_reply.started":"2023-01-15T04:36:08.583071Z","shell.execute_reply":"2023-01-15T04:36:08.707869Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Loss: 0.10310974575224377, Accuracy: 96.8452380952381% (8135/8400)\n","output_type":"stream"}]},{"cell_type":"code","source":"test = pd.read_csv(r\"/kaggle/input/digit-recognizer/test.csv\",dtype = np.float32)\ntest_targets_numpy = test.loc[:,test.columns != \"label\"].values/255 # normalization\ntargetsTest = torch.from_numpy(test_targets_numpy)\ntest = torch.utils.data.TensorDataset(targetsTest)\ntest_loader =  DataLoader(test, shuffle = False)","metadata":{"execution":{"iopub.status.busy":"2023-01-15T04:36:08.711058Z","iopub.execute_input":"2023-01-15T04:36:08.711449Z","iopub.status.idle":"2023-01-15T04:36:11.203061Z","shell.execute_reply.started":"2023-01-15T04:36:08.711410Z","shell.execute_reply":"2023-01-15T04:36:11.201764Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"pred = []\ncnt = 0\nfor x in test_loader:\n    with torch.no_grad():\n        output = model(x[0])\n    pred += [int(l.argmax()) for l in output]\n    cnt += 1","metadata":{"execution":{"iopub.status.busy":"2023-01-15T04:36:11.204575Z","iopub.execute_input":"2023-01-15T04:36:11.205109Z","iopub.status.idle":"2023-01-15T04:36:15.419879Z","shell.execute_reply.started":"2023-01-15T04:36:11.205056Z","shell.execute_reply":"2023-01-15T04:36:15.418813Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv('/kaggle/input/digit-recognizer/sample_submission.csv')\nsubmission['Label'] = pred\nsubmission.to_csv('submission.csv', index=False)\nsubmission.head(20)","metadata":{"execution":{"iopub.status.busy":"2023-01-15T04:36:15.421250Z","iopub.execute_input":"2023-01-15T04:36:15.421637Z","iopub.status.idle":"2023-01-15T04:36:15.486755Z","shell.execute_reply.started":"2023-01-15T04:36:15.421604Z","shell.execute_reply":"2023-01-15T04:36:15.485910Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"    ImageId  Label\n0         1      2\n1         2      0\n2         3      9\n3         4      9\n4         5      3\n5         6      7\n6         7      0\n7         8      3\n8         9      0\n9        10      3\n10       11      5\n11       12      7\n12       13      4\n13       14      0\n14       15      4\n15       16      3\n16       17      3\n17       18      1\n18       19      9\n19       20      0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ImageId</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>8</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>11</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>12</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>13</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>14</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>15</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>16</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>17</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>18</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>19</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>20</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}